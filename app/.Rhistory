mean,
order=T)
par(mar=c(4, 11, 2, 2))
beeswarm(word.count~FileOrdered,
data=sentence.list.sel,
horizontal = TRUE,
pch=16, col=alpha(brewer.pal(9, "Set1"), 0.6),
cex=0.55, cex.axis=0.8, cex.lab=0.8,
spacing=5/nlevels(sentence.list.sel$FileOrdered),
las=2, ylab="", xlab="Number of words in a sentence.",
main="Inaugural Speeches")
sentence.list%>%
filter(File=="BarackObama",
type=="inaug",
word.count<=3)%>%
select(sentences)
par(mfrow=c(4,1), mar=c(1,0,2,0), bty="n", xaxt="n", yaxt="n", font.main=1)
f.plotsent.len(In.list=sentence.list, InFile="HillaryClinton",
InType="nomin", InTerm=1, President="Hillary Clinton")
f.plotsent.len(In.list=sentence.list, InFile="DonaldJTrump",
InType="nomin", InTerm=1, President="Donald Trump")
f.plotsent.len(In.list=sentence.list, InFile="BarackObama",
InType="nomin", InTerm=1, President="Barack Obama")
f.plotsent.len(In.list=sentence.list, InFile="GeorgeWBush",
InType="nomin", InTerm=1, President="George W. Bush")
print("Hillary Clinton")
speech.df=tbl_df(sentence.list)%>%
filter(File=="HillaryClinton", type=="nomin", word.count>=4)%>%
select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
print("Barack Obama")
speech.df=tbl_df(sentence.list)%>%
filter(File=="BarackObama", type=="nomin", Term==1, word.count>=5)%>%
select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
print("George W Bush")
speech.df=tbl_df(sentence.list)%>%
filter(File=="GeorgeWBush", type=="nomin", Term==1, word.count>=4)%>%
select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
print("Donald Trump")
speech.df=tbl_df(sentence.list)%>%
filter(File=="DonaldJTrump", type=="nomin", Term==1, word.count>=5)%>%
select(sentences, anger:trust)
speech.df=as.data.frame(speech.df)
as.character(speech.df$sentences[apply(speech.df[,-1], 2, which.max)])
heatmap.2(cor(sentence.list%>%filter(type=="inaug")%>%select(anger:trust)),
scale = "none",
col = bluered(100), , margin=c(6, 6), key=F,
trace = "none", density.info = "none")
par(mar=c(4, 6, 2, 1))
emo.means=colMeans(select(sentence.list, anger:trust)>0.01)
col.use=c("red2", "darkgoldenrod1",
"chartreuse3", "blueviolet",
"darkgoldenrod2", "dodgerblue3",
"darkgoldenrod1", "darkgoldenrod1")
barplot(emo.means[order(emo.means)], las=2, col=col.use[order(emo.means)], horiz=T, main="Inaugural Speeches")
presid.summary=tbl_df(sentence.list)%>%
filter(type=="nomin", File%in%sel.comparison)%>%
#group_by(paste0(type, File))%>%
group_by(File)%>%
summarise(
anger=mean(anger),
anticipation=mean(anticipation),
disgust=mean(disgust),
fear=mean(fear),
joy=mean(joy),
sadness=mean(sadness),
surprise=mean(surprise),
trust=mean(trust)
#negative=mean(negative),
#positive=mean(positive)
)
presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(presid.summary[,-1], iter.max=200,
5)
fviz_cluster(km.res,
stand=F, repel= TRUE,
data = presid.summary[,-1], xlab="", xaxt="n",
show.clust.cent=FALSE)
corpus.list=sentence.list[2:(nrow(sentence.list)-1), ]
sentence.pre=sentence.list$sentences[1:(nrow(sentence.list)-2)]
sentence.post=sentence.list$sentences[3:(nrow(sentence.list)-1)]
corpus.list$snipets=paste(sentence.pre, corpus.list$sentences, sentence.post, sep=" ")
rm.rows=(1:nrow(corpus.list))[corpus.list$sent.id==1]
rm.rows=c(rm.rows, rm.rows-1)
corpus.list=corpus.list[-rm.rows, ]
docs <- Corpus(VectorSource(corpus.list$snipets))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
docs <-tm_map(docs,content_transformer(tolower))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
#remove punctuation
docs <- tm_map(docs, removePunctuation)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
#Strip digits
docs <- tm_map(docs, removeNumbers)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
#remove stopwords
docs <- tm_map(docs, removeWords, stopwords("english"))
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
#remove whitespace
docs <- tm_map(docs, stripWhitespace)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
#Stem document
docs <- tm_map(docs,stemDocument)
writeLines(as.character(docs[[sample(1:nrow(corpus.list), 1)]]))
dtm <- DocumentTermMatrix(docs)
#convert rownames to filenames#convert rownames to filenames
rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
corpus.list$Term, corpus.list$sent.id, sep="_")
rowTotals <- apply(dtm , 1, sum) #Find the sum of words in each Document
dtm  <- dtm[rowTotals> 0, ]
corpus.list=corpus.list[rowTotals>0, ]
corpus.list$sent.id, sep="_")
dtm <- DocumentTermMatrix(docs)
#convert rownames to filenames
rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
corpus.list$Term, corpus.list$sent.id, sep="_")
dtm <- DocumentTermMatrix(docs)
rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
corpus.list$Term, corpus.list$sent.id, sep="_")
View(corpus.list)
paste(corpus.list$type, corpus.list$File,
corpus.list$Term, corpus.list$sent.id, sep="_")
rownames(dtm) <- paste(corpus.list$type, corpus.list$File,
corpus.list$Term, corpus.list$sent.id, sep="_")
nrow(dtm)
rowTotals <- apply(dtm , 1, sum)
dtm  <- dtm[rowTotals> 0, ]
corpus.list=corpus.list[rowTotals>0, ]
burnin <- 4000
iter <- 2000
thin <- 500
seed <-list(2003,5,63,100001,765)
nstart <- 5
best <- TRUE
#Number of topics
k <- 15
#Run LDA using Gibbs sampling
ldaOut <-LDA(dtm, k, method="Gibbs", control=list(nstart=nstart,
seed = seed, best=best,
burnin = burnin, iter = iter,
thin=thin))
#write out results
#docs to topics
ldaOut.topics <- as.matrix(topics(ldaOut))
table(c(1:k, ldaOut.topics))
write.csv(ldaOut.topics,file=paste("../out/LDAGibbs",k,"DocsToTopics.csv"))
#top 6 terms in each topic
ldaOut.terms <- as.matrix(terms(ldaOut,20))
write.csv(ldaOut.terms,file=paste("../out/LDAGibbs",k,"TopicsToTerms.csv"))
#probabilities associated with each topic assignment
topicProbabilities <- as.data.frame(ldaOut@gamma)
write.csv(topicProbabilities,file=paste("../out/LDAGibbs",k,"TopicProbabilities.csv"))
terms.beta=ldaOut@beta
terms.beta=scale(terms.beta)
topics.terms=NULL
for(i in 1:k){
topics.terms=rbind(topics.terms, ldaOut@terms[order(terms.beta[i,], decreasing = TRUE)[1:7]])
}
topics.terms
ldaOut.terms
topics.hash=c("Economy", "America", "Defense", "Belief", "Election", "Patriotism", "Unity", "Government", "Reform", "Temporal", "WorkingFamilies", "Freedom", "Equality", "Misc", "Legislation")
corpus.list$ldatopic=as.vector(ldaOut.topics)
corpus.list$ldahash=topics.hash[ldaOut.topics]
colnames(topicProbabilities)=topics.hash
corpus.list.df=cbind(corpus.list, topicProbabilities)
par(mar=c(1,1,1,1))
topic.summary=tbl_df(corpus.list.df)%>%
filter(type%in%c("nomin", "inaug"), File%in%sel.comparison)%>%
select(File, Economy:Legislation)%>%
group_by(File)%>%
summarise_each(funs(mean))
topic.summary=as.data.frame(topic.summary)
rownames(topic.summary)=topic.summary[,1]
# [1] "Economy"         "America"         "Defense"         "Belief"
# [5] "Election"        "Patriotism"      "Unity"           "Government"
# [9] "Reform"          "Temporal"        "WorkingFamilies" "Freedom"
# [13] "Equality"        "Misc"            "Legislation"
topic.plot=c(1, 13, 9, 11, 8, 3, 7)
print(topics.hash[topic.plot])
heatmap.2(as.matrix(topic.summary[,topic.plot+1]),
scale = "column", key=F,
col = bluered(100),
cexRow = 0.9, cexCol = 0.9, margins = c(8, 8),
trace = "none", density.info = "none")
# [1] "Economy"         "America"         "Defense"         "Belief"
# [5] "Election"        "Patriotism"      "Unity"           "Government"
# [9] "Reform"          "Temporal"        "WorkingFamilies" "Freedom"
# [13] "Equality"        "Misc"            "Legislation"
par(mfrow=c(5, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
print(topics.hash[topic.plot])
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeBush", type=="nomin",Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="WilliamJClinton", type=="nomin", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Bill Clinton, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeWBush", type=="nomin", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George W Bush, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="BarackObama", type=="nomin", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Barack Obama, Nomination")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="DonaldJTrump", type=="nomin")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Donald Trump, Nomination")
# [1] "Economy"         "America"         "Defense"         "Belief"
# [5] "Election"        "Patriotism"      "Unity"           "Government"
# [9] "Reform"          "Temporal"        "WorkingFamilies" "Freedom"
# [13] "Equality"        "Misc"            "Legislation"
par(mfrow=c(5, 1), mar=c(1,1,2,0), bty="n", xaxt="n", yaxt="n")
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
print(topics.hash[topic.plot])
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeBush", type=="inaug", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, inaugural Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="WilliamJClinton", type=="inaug", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="William J Clinton, inaugural Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeWBush", type=="inaug", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George W. Bush, inaugural Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="BarackObama", type=="inaug", Term==1)%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Barack Obama, inaugural Speeches")
# [1] "Economy"         "America"         "Defense"         "Belief"
# [5] "Election"        "Patriotism"      "Unity"           "Government"
# [9] "Reform"          "Temporal"        "WorkingFamilies" "Freedom"
# [13] "Equality"        "Misc"            "Legislation"
par(mfrow=c(5, 1))
topic.plot=c(1, 13, 14, 15, 8, 9, 12)
print(topics.hash[topic.plot])
speech.df=tbl_df(corpus.list.df)%>%filter(File=="RonaldReagan", type=="farewell")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Ronald Reagan, Farewell Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeBush", type=="farewell")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George Bush, Farewell Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="WilliamJClinton", type=="farewell")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="William J. Clinton, Farewell Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="GeorgeWBush", type=="farewell")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="George W Bush, Farewell Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(File=="BarackObama", type=="farewell")%>%select(sent.id, Economy:Legislation)
speech.df=as.matrix(speech.df)
speech.df[,-1]=replace(speech.df[,-1], speech.df[,-1]<1/15, 0.001)
speech.df[,-1]=f.smooth.topic(x=speech.df[,1], y=speech.df[,-1])
plot.stacked(speech.df[,1], speech.df[,topic.plot+1],
xlab="Sentences", ylab="Topic share", main="Barack Obama, Farewell Speeches")
speech.df=tbl_df(corpus.list.df)%>%filter(type=="nomin", word.count<20)%>%select(sentences, Economy:Legislation)
as.character(speech.df$sentences[apply(as.data.frame(speech.df[,-1]), 2, which.max)])
names(speech.df)[-1]
presid.summary=tbl_df(corpus.list.df)%>%
filter(type=="inaug", File%in%sel.comparison)%>%
select(File, Economy:Legislation)%>%
group_by(File)%>%
summarise_each(funs(mean))
presid.summary=as.data.frame(presid.summary)
rownames(presid.summary)=as.character((presid.summary[,1]))
km.res=kmeans(scale(presid.summary[,-1]), iter.max=200,
5)
fviz_cluster(km.res,
stand=T, repel= TRUE,
data = presid.summary[,-1],
show.clust.cent=FALSE)
knitr::opts_chunk$set(echo = TRUE)
library("qdap")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
library("rvest")
library("rvest")
library("tibble")
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE,
repos='http://cran.us.r-project.org')
}
library(tm)
library(wordcloud)
library(RColorBrewer)
library(dplyr)
library(tidytext)
print(R.version)
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
install.packages(c("adabag", "backports", "boot", "caret", "ddalpha", "digest", "DRR", "DT", "foreach", "glue", "hms", "ISLR", "iterators", "itsmr", "knitr", "lava", "lazyeval", "lme4", "lubridate", "MASS", "Matrix", "mgcv", "mvtnorm", "purrr", "Rcpp", "recipes", "reshape2", "rlang", "rmarkdown", "robustbase", "rpart", "rprojroot", "stringi", "tibble", "tidyselect", "timeDate", "withr", "xml2", "yaml"))
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
knitr::opts_chunk$set(echo = TRUE)
packages.used=c("rvest", "tibble", "qdap",
"sentimentr", "gplots", "dplyr",
"tm", "syuzhet", "factoextra",
"beeswarm", "scales", "RColorBrewer",
"RANN", "tm", "topicmodels")
# check packages that need to be installed.
packages.needed=setdiff(packages.used,
intersect(installed.packages()[,1],
packages.used))
# install additional packages
if(length(packages.needed)>0){
install.packages(packages.needed, dependencies = TRUE)
}
# load packages
library("rvest")
library("tibble")
# You may need to run
# sudo ln -f -s $(/usr/libexec/java_home)/jre/lib/server/libjvm.dylib /usr/local/lib
# in order to load qdap
library("qdap")
library("sentimentr")
library("gplots")
library("dplyr")
library("tm")
library("syuzhet")
library("factoextra")
library("beeswarm")
library("scales")
library("RColorBrewer")
library("RANN")
library("tm")
library("topicmodels")
source("../lib/plotstacked.R")
source("../lib/speechFuncs.R")
install.packages("rJava")
install.packages("rJava")
knitr::opts_chunk$set(echo = TRUE)
library("rJava")
knitr::opts_chunk$set(echo = TRUE)
1000/exp(4*0.042)
(845.3538-828)/828
sum(logr)
set.seed(2012)
n=253
par(mfrow=c(3,3))
for (i in (1:9)){
logr = rnorm(n, 0.05 / 253, 0.2 / sqrt(253))
price = c(120, 120 * exp(cumsum(logr)))
plot(price, type = "b")
}
#The mean of the log-returns for 1 year is
sum(logr)
#The standard deviation of the log-returns for 1 year is
sd(logr)
shiny::runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Desktop/5243/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
?cheboxinput
?checkBoxInput
?checkboxInput
runApp('Documents/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
?radio
runApp('Documents/Spring2018-Project2-Group3/app')
runApp('Documents/Spring2018-Project2-Group3/app')
setwd("~/Documents/Spring2018-Project2-Group3/app")
shiny::runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
shiny::runApp()
runApp()
runApp()
shiny::runApp()
